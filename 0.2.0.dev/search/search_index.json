{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Kedata Text Analysis Package \u00b6 Skeleton project created by Python Project Wizard (ppw) Free software: MIT Documentation: https://canggihpw.github.io/kedatatext/ Features \u00b6 TODO Credits \u00b6 This package was created with the ppw tool. For more information, please visit the project page .","title":"home"},{"location":"#kedata-text-analysis-package","text":"Skeleton project created by Python Project Wizard (ppw) Free software: MIT Documentation: https://canggihpw.github.io/kedatatext/","title":"Kedata Text Analysis Package"},{"location":"#features","text":"TODO","title":"Features"},{"location":"#credits","text":"This package was created with the ppw tool. For more information, please visit the project page .","title":"Credits"},{"location":"api/","text":"clean_sentence_indonesia ( text , to_lower = True , use_stemming = True , remove_stopwords = True , remove_punctuation = True , remove_numbers = True , remove_urls = True , remove_mentions = True , remove_hashtags = True , remove_retweet = True , remove_extra_whitespace = True ) \u00b6 Cleans a text sentence by applying various preprocessing techniques. Parameters: Name Type Description Default text str The input text sentence. required to_lower bool Whether to convert the text to lowercase. Defaults to True. True use_stemming bool Whether to apply stemming to words. Defaults to True. True remove_stopwords bool Whether to remove Indonesian stop words. Defaults to True. True remove_punctuation bool Whether to remove punctuation characters. Defaults to True. True remove_numbers bool Whether to remove numeric characters. Defaults to True. True remove_urls bool Whether to remove URLs. Defaults to True. True remove_mentions bool Whether to remove mentions (starting with \"@\"). Defaults to True. True remove_hashtags bool Whether to remove hashtags (starting with \"#\"). Defaults to True. True remove_retweet bool Whether to remove \"RT\" at the beginning of retweets. Defaults to True. True remove_extra_whitespace bool Whether to remove extra whitespace characters. Defaults to True. True Returns: Name Type Description str str The cleaned text sentence. Examples: >>> text = \"RT @canggih: Mereka lihat ini: https://example.com\" >>> cleaned_text = clean_sentence_indonesia ( text , remove_urls = True , remove_mentions = True , remove_hashtags = True ) >>> print ( cleaned_text ) mereka lihat ini Notes This function uses the Sastrawi library for stemming. Consider adjusting the parameters based on your specific requirements. Source code in kedatatext/preprocessing.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 def clean_sentence_indonesia ( text : str , to_lower : bool = True , use_stemming : bool = True , remove_stopwords : bool = True , remove_punctuation : bool = True , remove_numbers : bool = True , remove_urls : bool = True , remove_mentions : bool = True , remove_hashtags : bool = True , remove_retweet : bool = True , remove_extra_whitespace : bool = True , ) -> str : \"\"\" Cleans a text sentence by applying various preprocessing techniques. Args: text (str): The input text sentence. to_lower (bool, optional): Whether to convert the text to lowercase. Defaults to True. use_stemming (bool, optional): Whether to apply stemming to words. Defaults to True. remove_stopwords (bool, optional): Whether to remove Indonesian stop words. Defaults to True. remove_punctuation (bool, optional): Whether to remove punctuation characters. Defaults to True. remove_numbers (bool, optional): Whether to remove numeric characters. Defaults to True. remove_urls (bool, optional): Whether to remove URLs. Defaults to True. remove_mentions (bool, optional): Whether to remove mentions (starting with \"@\"). Defaults to True. remove_hashtags (bool, optional): Whether to remove hashtags (starting with \"#\"). Defaults to True. remove_retweet (bool, optional): Whether to remove \"RT\" at the beginning of retweets. Defaults to True. remove_extra_whitespace (bool, optional): Whether to remove extra whitespace characters. Defaults to True. Returns: str: The cleaned text sentence. Examples: >>> text = \"RT @canggih: Mereka lihat ini: https://example.com\" >>> cleaned_text = clean_sentence_indonesia(text, remove_urls=True, remove_mentions=True, remove_hashtags=True) >>> print(cleaned_text) mereka lihat ini Notes: - This function uses the `Sastrawi` library for stemming. - Consider adjusting the parameters based on your specific requirements. \"\"\" # Remove RT if remove_retweet : if text . startswith ( \"RT \" ): text = text [ 3 :] . strip () # Remove URLs if remove_urls : text = re . sub ( r \"http\\S+\" , \"\" , text ) # Remove mentions if remove_mentions : text = re . sub ( \"@[A-Za-z0-9]+\" , \"\" , text ) # Remove hashtags if remove_hashtags : text = re . sub ( \"#\" , \"\" , text ) # Remove numbers if remove_numbers : text = re . sub ( r \"\\d+\" , \"\" , text ) # Convert to lowercase if to_lower : text = text . lower () # Remove extra whitespace if remove_extra_whitespace : text = \" \" . join ( text . split ()) # Remove punctuation if remove_punctuation : text = text . translate ( str . maketrans ( \"\" , \"\" , string . punctuation )) # Remove stop words if remove_stopwords : stop_words = set ( stopwords . words ( \"indonesian\" )) word_tokens = word_tokenize ( text ) filtered_sentence = [ word for word in word_tokens if word not in stop_words ] text = \" \" . join ( filtered_sentence ) # Stemming if use_stemming : text = stemmer . stem ( text ) return text clean_sentences_indonesia ( list_of_texts , to_lower = True , use_stemming = True , remove_stopwords = True , remove_punctuation = True , remove_numbers = True , remove_urls = True , remove_mentions = True , remove_hashtags = True , remove_retweet = True , remove_extra_whitespace = True ) \u00b6 Cleans a list of text sentences by applying various preprocessing techniques. Parameters: Name Type Description Default list_of_texts List [ str ] A list of input text sentences. required to_lower bool Whether to convert the text to lowercase. Defaults to True. True use_stemming bool Whether to apply stemming to words. Defaults to True. True remove_stopwords bool Whether to remove Indonesian stop words. Defaults to True. True remove_punctuation bool Whether to remove punctuation characters. Defaults to True. True remove_numbers bool Whether to remove numeric characters. Defaults to True. True remove_urls bool Whether to remove URLs. Defaults to True. True remove_mentions bool Whether to remove mentions (starting with \"@\"). Defaults to True. True remove_hashtags bool Whether to remove hashtags (starting with \"#\"). Defaults to True. True remove_retweet bool Whether to remove \"RT\" at the beginning of retweets. Defaults to True. True remove_extra_whitespace bool Whether to remove extra whitespace characters. Defaults to True. True Returns: Type Description List [ str ] List[str]: A list of cleaned text sentences. Examples: >>> list_of_texts = [ \"RT @canggih: Mereka lihat ini: https://example.com\" , \"Halo 123!\" ] >>> cleaned_texts = clean_sentences_indonesia ( list_of_texts ) >>> print ( cleaned_texts ) ['mereka lihat ini', 'halo'] Source code in kedatatext/preprocessing.py 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 def clean_sentences_indonesia ( list_of_texts : List [ str ], to_lower : bool = True , use_stemming : bool = True , remove_stopwords : bool = True , remove_punctuation : bool = True , remove_numbers : bool = True , remove_urls : bool = True , remove_mentions : bool = True , remove_hashtags : bool = True , remove_retweet : bool = True , remove_extra_whitespace : bool = True , ) -> List [ str ]: \"\"\" Cleans a list of text sentences by applying various preprocessing techniques. Args: list_of_texts (List[str]): A list of input text sentences. to_lower (bool, optional): Whether to convert the text to lowercase. Defaults to True. use_stemming (bool, optional): Whether to apply stemming to words. Defaults to True. remove_stopwords (bool, optional): Whether to remove Indonesian stop words. Defaults to True. remove_punctuation (bool, optional): Whether to remove punctuation characters. Defaults to True. remove_numbers (bool, optional): Whether to remove numeric characters. Defaults to True. remove_urls (bool, optional): Whether to remove URLs. Defaults to True. remove_mentions (bool, optional): Whether to remove mentions (starting with \"@\"). Defaults to True. remove_hashtags (bool, optional): Whether to remove hashtags (starting with \"#\"). Defaults to True. remove_retweet (bool, optional): Whether to remove \"RT\" at the beginning of retweets. Defaults to True. remove_extra_whitespace (bool, optional): Whether to remove extra whitespace characters. Defaults to True. Returns: List[str]: A list of cleaned text sentences. Examples: >>> list_of_texts = [\"RT @canggih: Mereka lihat ini: https://example.com\", \"Halo 123!\"] >>> cleaned_texts = clean_sentences_indonesia(list_of_texts) >>> print(cleaned_texts) ['mereka lihat ini', 'halo'] \"\"\" return [ clean_sentence_indonesia ( text , to_lower , use_stemming , remove_stopwords , remove_punctuation , remove_numbers , remove_urls , remove_mentions , remove_hashtags , remove_retweet , remove_extra_whitespace , ) for text in list_of_texts ]","title":"Api dua"},{"location":"api/#kedatatext.preprocessing.clean_sentence_indonesia","text":"Cleans a text sentence by applying various preprocessing techniques. Parameters: Name Type Description Default text str The input text sentence. required to_lower bool Whether to convert the text to lowercase. Defaults to True. True use_stemming bool Whether to apply stemming to words. Defaults to True. True remove_stopwords bool Whether to remove Indonesian stop words. Defaults to True. True remove_punctuation bool Whether to remove punctuation characters. Defaults to True. True remove_numbers bool Whether to remove numeric characters. Defaults to True. True remove_urls bool Whether to remove URLs. Defaults to True. True remove_mentions bool Whether to remove mentions (starting with \"@\"). Defaults to True. True remove_hashtags bool Whether to remove hashtags (starting with \"#\"). Defaults to True. True remove_retweet bool Whether to remove \"RT\" at the beginning of retweets. Defaults to True. True remove_extra_whitespace bool Whether to remove extra whitespace characters. Defaults to True. True Returns: Name Type Description str str The cleaned text sentence. Examples: >>> text = \"RT @canggih: Mereka lihat ini: https://example.com\" >>> cleaned_text = clean_sentence_indonesia ( text , remove_urls = True , remove_mentions = True , remove_hashtags = True ) >>> print ( cleaned_text ) mereka lihat ini Notes This function uses the Sastrawi library for stemming. Consider adjusting the parameters based on your specific requirements. Source code in kedatatext/preprocessing.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 def clean_sentence_indonesia ( text : str , to_lower : bool = True , use_stemming : bool = True , remove_stopwords : bool = True , remove_punctuation : bool = True , remove_numbers : bool = True , remove_urls : bool = True , remove_mentions : bool = True , remove_hashtags : bool = True , remove_retweet : bool = True , remove_extra_whitespace : bool = True , ) -> str : \"\"\" Cleans a text sentence by applying various preprocessing techniques. Args: text (str): The input text sentence. to_lower (bool, optional): Whether to convert the text to lowercase. Defaults to True. use_stemming (bool, optional): Whether to apply stemming to words. Defaults to True. remove_stopwords (bool, optional): Whether to remove Indonesian stop words. Defaults to True. remove_punctuation (bool, optional): Whether to remove punctuation characters. Defaults to True. remove_numbers (bool, optional): Whether to remove numeric characters. Defaults to True. remove_urls (bool, optional): Whether to remove URLs. Defaults to True. remove_mentions (bool, optional): Whether to remove mentions (starting with \"@\"). Defaults to True. remove_hashtags (bool, optional): Whether to remove hashtags (starting with \"#\"). Defaults to True. remove_retweet (bool, optional): Whether to remove \"RT\" at the beginning of retweets. Defaults to True. remove_extra_whitespace (bool, optional): Whether to remove extra whitespace characters. Defaults to True. Returns: str: The cleaned text sentence. Examples: >>> text = \"RT @canggih: Mereka lihat ini: https://example.com\" >>> cleaned_text = clean_sentence_indonesia(text, remove_urls=True, remove_mentions=True, remove_hashtags=True) >>> print(cleaned_text) mereka lihat ini Notes: - This function uses the `Sastrawi` library for stemming. - Consider adjusting the parameters based on your specific requirements. \"\"\" # Remove RT if remove_retweet : if text . startswith ( \"RT \" ): text = text [ 3 :] . strip () # Remove URLs if remove_urls : text = re . sub ( r \"http\\S+\" , \"\" , text ) # Remove mentions if remove_mentions : text = re . sub ( \"@[A-Za-z0-9]+\" , \"\" , text ) # Remove hashtags if remove_hashtags : text = re . sub ( \"#\" , \"\" , text ) # Remove numbers if remove_numbers : text = re . sub ( r \"\\d+\" , \"\" , text ) # Convert to lowercase if to_lower : text = text . lower () # Remove extra whitespace if remove_extra_whitespace : text = \" \" . join ( text . split ()) # Remove punctuation if remove_punctuation : text = text . translate ( str . maketrans ( \"\" , \"\" , string . punctuation )) # Remove stop words if remove_stopwords : stop_words = set ( stopwords . words ( \"indonesian\" )) word_tokens = word_tokenize ( text ) filtered_sentence = [ word for word in word_tokens if word not in stop_words ] text = \" \" . join ( filtered_sentence ) # Stemming if use_stemming : text = stemmer . stem ( text ) return text","title":"clean_sentence_indonesia"},{"location":"api/#kedatatext.preprocessing.clean_sentences_indonesia","text":"Cleans a list of text sentences by applying various preprocessing techniques. Parameters: Name Type Description Default list_of_texts List [ str ] A list of input text sentences. required to_lower bool Whether to convert the text to lowercase. Defaults to True. True use_stemming bool Whether to apply stemming to words. Defaults to True. True remove_stopwords bool Whether to remove Indonesian stop words. Defaults to True. True remove_punctuation bool Whether to remove punctuation characters. Defaults to True. True remove_numbers bool Whether to remove numeric characters. Defaults to True. True remove_urls bool Whether to remove URLs. Defaults to True. True remove_mentions bool Whether to remove mentions (starting with \"@\"). Defaults to True. True remove_hashtags bool Whether to remove hashtags (starting with \"#\"). Defaults to True. True remove_retweet bool Whether to remove \"RT\" at the beginning of retweets. Defaults to True. True remove_extra_whitespace bool Whether to remove extra whitespace characters. Defaults to True. True Returns: Type Description List [ str ] List[str]: A list of cleaned text sentences. Examples: >>> list_of_texts = [ \"RT @canggih: Mereka lihat ini: https://example.com\" , \"Halo 123!\" ] >>> cleaned_texts = clean_sentences_indonesia ( list_of_texts ) >>> print ( cleaned_texts ) ['mereka lihat ini', 'halo'] Source code in kedatatext/preprocessing.py 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 def clean_sentences_indonesia ( list_of_texts : List [ str ], to_lower : bool = True , use_stemming : bool = True , remove_stopwords : bool = True , remove_punctuation : bool = True , remove_numbers : bool = True , remove_urls : bool = True , remove_mentions : bool = True , remove_hashtags : bool = True , remove_retweet : bool = True , remove_extra_whitespace : bool = True , ) -> List [ str ]: \"\"\" Cleans a list of text sentences by applying various preprocessing techniques. Args: list_of_texts (List[str]): A list of input text sentences. to_lower (bool, optional): Whether to convert the text to lowercase. Defaults to True. use_stemming (bool, optional): Whether to apply stemming to words. Defaults to True. remove_stopwords (bool, optional): Whether to remove Indonesian stop words. Defaults to True. remove_punctuation (bool, optional): Whether to remove punctuation characters. Defaults to True. remove_numbers (bool, optional): Whether to remove numeric characters. Defaults to True. remove_urls (bool, optional): Whether to remove URLs. Defaults to True. remove_mentions (bool, optional): Whether to remove mentions (starting with \"@\"). Defaults to True. remove_hashtags (bool, optional): Whether to remove hashtags (starting with \"#\"). Defaults to True. remove_retweet (bool, optional): Whether to remove \"RT\" at the beginning of retweets. Defaults to True. remove_extra_whitespace (bool, optional): Whether to remove extra whitespace characters. Defaults to True. Returns: List[str]: A list of cleaned text sentences. Examples: >>> list_of_texts = [\"RT @canggih: Mereka lihat ini: https://example.com\", \"Halo 123!\"] >>> cleaned_texts = clean_sentences_indonesia(list_of_texts) >>> print(cleaned_texts) ['mereka lihat ini', 'halo'] \"\"\" return [ clean_sentence_indonesia ( text , to_lower , use_stemming , remove_stopwords , remove_punctuation , remove_numbers , remove_urls , remove_mentions , remove_hashtags , remove_retweet , remove_extra_whitespace , ) for text in list_of_texts ]","title":"clean_sentences_indonesia"},{"location":"authors/","text":"Credits \u00b6 Development Lead \u00b6 Canggih Puspo Wibowo cangcappo@gmail.com Contributors \u00b6 None yet. Why not be the first?","title":"authors"},{"location":"authors/#credits","text":"","title":"Credits"},{"location":"authors/#development-lead","text":"Canggih Puspo Wibowo cangcappo@gmail.com","title":"Development Lead"},{"location":"authors/#contributors","text":"None yet. Why not be the first?","title":"Contributors"},{"location":"contributing/","text":"Contributing \u00b6 Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. You can contribute in many ways: Types of Contributions \u00b6 Report Bugs \u00b6 Report bugs at https://github.com/canggihpw/kedatatext/issues. If you are reporting a bug, please include: Your operating system name and version. Any details about your local setup that might be helpful in troubleshooting. Detailed steps to reproduce the bug. Fix Bugs \u00b6 Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it. Implement Features \u00b6 Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it. Write Documentation \u00b6 Kedata Text Analysis Package could always use more documentation, whether as part of the official Kedata Text Analysis Package docs, in docstrings, or even on the web in blog posts, articles, and such. Submit Feedback \u00b6 The best way to send feedback is to file an issue at https://github.com/canggihpw/kedatatext/issues. If you are proposing a feature: Explain in detail how it would work. Keep the scope as narrow as possible, to make it easier to implement. Remember that this is a volunteer-driven project, and that contributions are welcome :) Get Started! \u00b6 Ready to contribute? Here's how to set up kedatatext for local development. Fork the kedatatext repo on GitHub. Clone your fork locally 1 $ git clone git@github.com:your_name_here/kedatatext.git Ensure poetry is installed. Install dependencies and start your virtualenv: 1 $ poetry install -E test -E doc -E dev Create a branch for local development: 1 $ git checkout -b name-of-your-bugfix-or-feature Now you can make your changes locally. When you're done making changes, check that your changes pass the tests, including testing other Python versions, with tox: 1 $ tox Commit your changes and push your branch to GitHub: 1 2 3 $ git add . $ git commit -m \"Your detailed description of your changes.\" $ git push origin name-of-your-bugfix-or-feature Submit a pull request through the GitHub website. Pull Request Guidelines \u00b6 Before you submit a pull request, check that it meets these guidelines: The pull request should include tests. If the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring, and add the feature to the list in README.md. The pull request should work for Python 3.6, 3.7, 3.8, 3.9 and for PyPy. Check https://github.com/canggihpw/kedatatext/actions and make sure that the tests pass for all supported Python versions. Tips``` \u00b6 1 $ pytest tests.test_kedatatext ```To run a subset of tests. Deploying \u00b6 A reminder for the maintainers on how to deploy. Make sure all your changes are committed (including an entry in HISTORY.md). Then run: 1 2 3 $ poetry patch # possible: major / minor / patch $ git push $ git push --tags Github Actions will then deploy to PyPI if tests pass.","title":"contributing"},{"location":"contributing/#contributing","text":"Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. You can contribute in many ways:","title":"Contributing"},{"location":"contributing/#types-of-contributions","text":"","title":"Types of Contributions"},{"location":"contributing/#report-bugs","text":"Report bugs at https://github.com/canggihpw/kedatatext/issues. If you are reporting a bug, please include: Your operating system name and version. Any details about your local setup that might be helpful in troubleshooting. Detailed steps to reproduce the bug.","title":"Report Bugs"},{"location":"contributing/#fix-bugs","text":"Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it.","title":"Fix Bugs"},{"location":"contributing/#implement-features","text":"Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it.","title":"Implement Features"},{"location":"contributing/#write-documentation","text":"Kedata Text Analysis Package could always use more documentation, whether as part of the official Kedata Text Analysis Package docs, in docstrings, or even on the web in blog posts, articles, and such.","title":"Write Documentation"},{"location":"contributing/#submit-feedback","text":"The best way to send feedback is to file an issue at https://github.com/canggihpw/kedatatext/issues. If you are proposing a feature: Explain in detail how it would work. Keep the scope as narrow as possible, to make it easier to implement. Remember that this is a volunteer-driven project, and that contributions are welcome :)","title":"Submit Feedback"},{"location":"contributing/#get-started","text":"Ready to contribute? Here's how to set up kedatatext for local development. Fork the kedatatext repo on GitHub. Clone your fork locally 1 $ git clone git@github.com:your_name_here/kedatatext.git Ensure poetry is installed. Install dependencies and start your virtualenv: 1 $ poetry install -E test -E doc -E dev Create a branch for local development: 1 $ git checkout -b name-of-your-bugfix-or-feature Now you can make your changes locally. When you're done making changes, check that your changes pass the tests, including testing other Python versions, with tox: 1 $ tox Commit your changes and push your branch to GitHub: 1 2 3 $ git add . $ git commit -m \"Your detailed description of your changes.\" $ git push origin name-of-your-bugfix-or-feature Submit a pull request through the GitHub website.","title":"Get Started!"},{"location":"contributing/#pull-request-guidelines","text":"Before you submit a pull request, check that it meets these guidelines: The pull request should include tests. If the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring, and add the feature to the list in README.md. The pull request should work for Python 3.6, 3.7, 3.8, 3.9 and for PyPy. Check https://github.com/canggihpw/kedatatext/actions and make sure that the tests pass for all supported Python versions.","title":"Pull Request Guidelines"},{"location":"contributing/#tips","text":"1 $ pytest tests.test_kedatatext ```To run a subset of tests.","title":"Tips```"},{"location":"contributing/#deploying","text":"A reminder for the maintainers on how to deploy. Make sure all your changes are committed (including an entry in HISTORY.md). Then run: 1 2 3 $ poetry patch # possible: major / minor / patch $ git push $ git push --tags Github Actions will then deploy to PyPI if tests pass.","title":"Deploying"},{"location":"history/","text":"History \u00b6 0.2.1 (2024-02-23) \u00b6 Restructure the preprocessing data model 0.2.0 (2024-02-22) \u00b6 Add preprocessing module Add preprocessing pytest Revise minor templates 0.1.0 (2024-02-21) \u00b6 First Setup","title":"history"},{"location":"history/#history","text":"","title":"History"},{"location":"history/#021-2024-02-23","text":"Restructure the preprocessing data model","title":"0.2.1 (2024-02-23)"},{"location":"history/#020-2024-02-22","text":"Add preprocessing module Add preprocessing pytest Revise minor templates","title":"0.2.0 (2024-02-22)"},{"location":"history/#010-2024-02-21","text":"First Setup","title":"0.1.0 (2024-02-21)"},{"location":"installation/","text":"Installation \u00b6 Stable release \u00b6 To install Kedata Text Analysis Package, run this command in your terminal: 1 pip install kedatatext This is the preferred method to install Kedata Text Analysis Package, as it will always install the most recent stable release. If you don't have pip installed, this Python installation guide can guide you through the process. From source \u00b6 The source for Kedata Text Analysis Package can be downloaded from the Github repo . You can either clone the public repository: 1 git clone git://github.com/canggihpw/kedatatext Or download the tarball : 1 curl -OJL https://github.com/canggihpw/kedatatext/tarball/master Once you have a copy of the source, you can install it with: 1 pip install .","title":"installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#stable-release","text":"To install Kedata Text Analysis Package, run this command in your terminal: 1 pip install kedatatext This is the preferred method to install Kedata Text Analysis Package, as it will always install the most recent stable release. If you don't have pip installed, this Python installation guide can guide you through the process.","title":"Stable release"},{"location":"installation/#from-source","text":"The source for Kedata Text Analysis Package can be downloaded from the Github repo . You can either clone the public repository: 1 git clone git://github.com/canggihpw/kedatatext Or download the tarball : 1 curl -OJL https://github.com/canggihpw/kedatatext/tarball/master Once you have a copy of the source, you can install it with: 1 pip install .","title":"From source"},{"location":"usage/","text":"Usage \u00b6 To use Kedata Text Analysis Package in a project 1 import kedatatext","title":"usage"},{"location":"usage/#usage","text":"To use Kedata Text Analysis Package in a project 1 import kedatatext","title":"Usage"}]}